\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,color,amssymb,amsthm,mathrsfs,verbatim,tikz,graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage{xcolor}
\usepackage{enumerate}
\usetikzlibrary{matrix,arrows,decorations.pathmorphing}
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem*{fact}{Fact}
\newtheorem{example}{Example}
\newtheorem*{ex}{Exercise}
\newtheorem*{soln}{Solution}
\newtheorem*{prob}{Problem}
\newtheorem*{lemma}{Lemma}

\theoremstyle{theorem}
\newtheorem{thm}{Theorem}

\newcommand{\R}{\mathbb{R}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\X}{\mathbb{X}}
\newcommand{\Y}{\mathbb{Y}}
\newcommand{\J}{\mathbb{J}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\K}{\mathbb{K}}
\renewcommand{\S}{\mathbb{S}}
\newcommand{\E}{\mathbb{\emptyset}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\Proj}{\mathbb{P}}
\newcommand{\HP}{\mathbb{H}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\Pic}{\mbox{Pic}}
\newcommand{\Div}{\mbox{Div}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\atan}{\operatorname{atan2}}
\newcommand{\acos}{\operatorname{acos}}


\begin{document}

\title{Advanced Calculus HW 11 - Due December 1, 4pm}
\author{Luis Berlioz}
\maketitle



\begin{prob}[\#9 page 198]
    Assume that $f: \R \to \R$ is differentiable.
    \begin{enumerate}[(a)]
        \item If there is an $L<1$ such that for each $x\in \R$ we have $f'(x)<L$, prove that there exists a unique point $x$ such that $f(x) =x$. [$x$ is a fixed point for $f$.]        
        \item Show by example that (a) fails if $L=1$.
    \end{enumerate}
\end{prob}
\begin{soln}
    \begin{enumerate}[(a)]
        \item If $f(0)=0$, then $x=0$ is a fixed point of $f$. In the case $f(0)>0$, then by the mean value theorem for all $x>0$ there exists a $0< c< x$ such that:
            $$f(x) - f(0) = f'(c)x < Lx < x$$
            This implies that:
            $$f(x) -x < f(0) +(L-1)x$$
            This shows that  in the interval $[0,f(0)/(1-L)]$, $f(x) -x$ is going from the positive value of $f(0)$ to some negative value at $x=f(0)/(1-L)$. By the intermediate value theorem, which $f(x) - x$ satisfies since it is continuous, $f$ must have a fixed point.

            Similarly for the case $f(0)<0$. For any $x<0$, by the mean value theorem:
            $$f(x) - f(0) = f'(c)x > Lx > x$$
            This implies:
            $$x-f(x) < (L-1)x -f(0)$$
            Therefore, $f$ has a fixed point in the interval $[f(0)/(1-L), 0]$.

            In every case the fixed point of $f$ is  unique because $(f(x)-x)' < L-1<0$. This means that the function is one to one so $f(x)-x$ can only be equal to zero once.

        \item Consider $f(x) = e^{-x } +x$. Then $f'(x) = -e^{-x }+1<1$ for all $x\in \R$. Observe that $f$ has no fixed point since the function: $f(x)-x = e^{-x }$ has no roots.
    \end{enumerate}
\end{soln}
\vspace{1in}



\begin{prob}[\#28 page 203   ]
    Suppose that $Z\subset \R$. Prove that the following are equivalent.
    \begin{enumerate}[(i)]
        \item $Z$ is a zero set.
        \item For each $\epsilon>0$ there is a countable covering of $Z$ by intervals $[a_i, b_i]$ with total length $\sum b_i - a_i <\epsilon$.
        \item For each $\epsilon>0$ there is a countable covering of $Z$ by set $S_i$ with total diameter $\sum diam\, S_i <\epsilon$.

    \end{enumerate}
\end{prob}
\begin{soln}
\begin{description}
    \item[(i) $\implies$ (ii)] The length of the open interval $]a,b[$ is the same as the length of the closed interval with the same limits $[a,b]$. This implies that for every $\epsilon >0$ $Z$ can be covered by open intervals $]a_i,b_i[$ for $i\in \N$ such that:
        $$\sum_{i\in \N }(b_i-a_i)<\epsilon $$
        The closed intervals $[a_i,b_i]$ for all $i\in \N$ also cover $Z$ and their lengths is also less than $\epsilon$.
    \item[(ii) $\implies$ (iii)] The diameter of a the closed intervals $S_i = [a_i, b_i]$ is $b_i -a_i$. If we take the same collection of intervals $[a_i,b_i]$ as above then we have a countable covering $S_i$ for all $i\in \N$ such that $\sum diam\, S_i <\epsilon$.
    \item[(iii)$\implies$ (i)] For any covering of $Z$ by sets $S_i$ for all $i\in \N$, for every $z\in Z$ there exists $S_j$ such that $z\in S_j$.  Let $a_j= \inf S_j$ and $b_j = \inf S_j$. This means that $diam \, S_j = b_j-a_j$ and that $S_j \subset ]a_j, b_j[$. Lastly, by hypothesis for all $\epsilon >0$  there exists a covering $S_i$  and sequences $a_i$ and $b_i$ defined as above such that:
        $$\sum (b_i - a_i) = \sum diam\, S_i < \epsilon$$
\end{description}
\end{soln}
\vspace{1in}


\begin{prob}[\# 40  page 205]
    Set:
    $$ f(x) = \begin{cases} 0 & \text{ if } x\leq 0\\
    \sin\frac \pi x & \text{ if } x>0\end{cases}\quad \text{ and }\quad g(x) =\begin{cases} 0 & \text{ if } x\leq 0\\
    1 & \text{ if } x>0\end{cases}  $$ 
    Prove that $f$ has an antiderivative but $g$ does not.
\end{prob}
\begin{soln}
    Observe that $f$ is bounded and it is only discontinuous at $x=0$. This means that it satisfies the hypothesis of the Lebesgue-Riemann theorem. Then $f$ is an integrable function and thus by the fundamental theorem of calculus it has an antiderivative. 

    On the other hand if $g$ were to have an antiderivative, then it would satisfy the intermediate value property. Since it does not for $0<y<1$ then it does not have an antiderivative.
\end{soln}
\vspace{1in}


\begin{prob}[\# 36  page 204]
    Generalizing Exercise 1.31, we say that $f:\ (a,b) \to \R$ has a \textbf{jump discontinuity} (or a discontiuity of the \textbf{first kind}) at $c\in (a,b)$ if:
    $$f(c^-) = \lim_{x\to c^- }f(x) \quad \text{and} f(c^+) = \lim_{x\to c^+ }f(x)$$
    exist, but are either unequal or are unequal to $f(c)$. (The three quantities exist and are equal if and only if $f$ is continuous at c.) An \textbf{oscillating discontinuity } (or a discontinuity of the \textbf{second kind} is any nonjump discontinuity.
    \begin{enumerate}[(a)]
        \item Show that $f:\ \R \to \R$ has at most countable many jump discontinuities.
        \item What about the function
            $$f(x) = \begin{cases} \sin \frac 1x & \text{if } x>0 \\
            0 & \text{if } x\leq 0 \end{cases}$$
        \item What about the characteristic function of the rationals?
    \end{enumerate}
\end{prob}
\begin{soln}
    \begin{enumerate}[(a)]
        \item If $f$ has a jump discontinuity at $c$, then $f(c^-) < f(c^+)$ or $f(c^+) < f(c^-)$. In either case, there exists a rational number $q$ between these two values. Next, take $N\in \N$ such that if $n>\N$ then:
            $$f(c-1/n) < q < f(c+1/n) \quad \text{or} \quad f(c-1/n) > q > f(c+1/n)$$
            The pairs $(N,q)$ enables to individualize each discontinuity. Since the set $(N,q)\in \N\times \Q$ is countable, then the set of all discontinuities is also countable.
        \item The function $f$ has an oscillating discontinuity at zero and is contuous on the rest of the real line. This is because $f(0^+)$ does not exist since for all $\delta>0$ there are $0<x_1<x_2<\delta$ such that $f(x_1)=1$ and $f(x_2)=-1$.
        \item Since both the set of rationals and irrationals are dense in $\R$, the limits at every point fail to exist. This means that there is an oscillating discontinuity at every point. 
    \end{enumerate}
\end{soln}
\vspace{1in}

\begin{prob}[\# 62  page 208]
    Prove that if the terms of a sequence decrease monotonically, $a_1 \geq a_2\geq \ldots$, and converge to 0 then the series $\sum a_k$ converges if and only if the associated dyadic series:
    $$a_1 + 2a_2 +4a_4 +8a_8 + \cdots = \sum 2^k a_{2^k }$$
    converges. (I call this the \textbf{block test} because it groups the terms of the series in blocks of length $2^{k-1 }$.)
\end{prob}
\begin{soln}
    That the $a_k$ are a monotinically decreasing sequence implies that for all $k>0$:
    $$ \sum_{j= 2^{k-1 }}^{2^k-1 }a_j \geq \sum_{j=2^{k-1 } }^{2^k-1 }a_{2^k } = (2^{k-1 }-1)a_{2^k }$$
    We call $s_k=\sum_{j= 2^{k-1 }}^{2^k-1 }a_j$ (this is the sum on the left above). Then for all $k>0$:
    $$2(s_k + a_{2^k }) \geq 2^ka_{2^k }$$
    Observe that $\sum s_k = \sum a_k$ (where we sum over $k>0$). Then if we assume that $\sum a_k$ converges then $\sum a_{2^k }$ also converges since it is a subset of an absolute converging sequence. Therefore  $\sum 2^k a_{2^k }$ converges.

    On the other hand, for $k >0$:
    $$a_{2^k }2^k \geq \sum_{j=2^k }^{2^{k+1 } }a_j \geq \sum_{j=2^k }^{2^{k+1 }-1 }a_j = r_k $$
    Assuming that $\sum a_{2^k }2^k $ converges implies that $\sum r_k = \sum a_k$ converges.
\end{soln}
\vspace{1in}

\end{document}








